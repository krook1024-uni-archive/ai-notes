\section{Döntési fák}

\begin{definicio}
    Információs rendszer.
    Egy {\bf információs rendszer} alatt egy $\mathcal{I} = \left<S, A, V, f \right>$
    négyest értünk, ahol
    \begin{itemize}
        \item $S$ az objektumok halmaza,
        \item $A = \{a_1, a_2, \ldots a_n\}$ attribútumok véges nemüres
            halmaza, ahol minden $a \in A$ attribútomhoz tartozik egy nemüres
            $V_a$ értékhalmaz (tartomány)
        \item $V$ az attribútumértékek halmaza: $V = \cup^k_{i=1} V_{a_i}$
        \item $f: S \times A \to V$ függvény úgy, hogy \[
                f(s, a) \in V_a \text{ minden } s \in S \text{ és }
                a \in A \text{ esetén}
        .\]
    \end{itemize}
\end{definicio}

\begin{definicio}
    Döntési tábla.
    {\bf Döntési tábla} alatt olyan $\left<\mathcal{I}, d \right>$
    rendezett párt értünk, ahol
    \begin{itemize}
        \item $\mathcal{I} = \left<S, A, V, f \right>$ egy információs
            rendszer,
        \item $d\in A$ a {\bf döntési attribútum}.
    \end{itemize}

    Ekkor az attribútumok $C = A \setminus \{d\}$ részhalmaza a {\bf feltétel
    attribútumok} (condition attributes) halmaza.
\end{definicio}

A döntési fa tanulás egyike a legegyszerűbb, mégis az eddigiekben az egyik
legsikeresebbnek bizonyult tanulási algoritmusnak. Jó bevezetésként szolgál az
induktív tanulás területén, és ráadásul könnyen implementálható. Először
bemutatjuk a cselekvő alrendszert, majd megmutatjuk, hogy miképpen lehet
tanítani. Mindeközben olyan elveket mutatunk be, amelyek az induktív tanulás
minden területére jellemzők.

\begin{definicio}
    Induktív tanulás.
    Cél, hogy pozitív és negatív példák alapján olyan logikai függvényt
    állítsunk elő, ami igaz értéket ad a pozitív és hamisat a negatív példákra
    és feltételezzük, hogy ha elég nagyszámú példánk van akkor helyes értéket
    fogunk kapni előre nem látott példák esetén is.
\end{definicio}

\begin{definicio}
    Döntési fa.

    Egy döntési fa (decision tree) bemenetként egy attribútumokkal (attributes)
    leírt objektumot vagy szituációt kap, és egy „döntést” ad vissza
    eredményként – a bemenetre adott válasz jósolt értékét. A bemeneti
    attribútumok lehetnek diszkrétek vagy folytonosak. Jelen tárgyalásban
    diszkrét bemeneteket tételezünk fel. A kimeneti érték szintén lehet
    diszkrét vagy folytonos; egy diszkrét értékkészletű függvény tanulását
    osztályozás (classification) tanulásnak, míg a folytonos függvény tanulását
    regressziónak (regression) nevezzük. Bináris (Boolean) osztályozásra fogunk
    koncentrálni, ahol minden példát vagy igaznak (pozitív), vagy hamisnak
    (negatív) sorolunk be.
\end{definicio}

\subsection{Az ID3 algoritmus}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwFunction{FIDthree}{ID3}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FIDthree{ $\mathcal{I}, d, S', C', b$ }}
    {
        \If{$S' = \varnothing$}{
            \KwRet{new-node-with-label($b$)}\;
        }

        $m \gets$ majority$(S', d)$ \;

        \If{ $A = \varnothing$ {\bf or} $\forall s \in S' : (f(s, d) = m)$}{
            \KwRet{new-node-with-label($m$)} \;
        }

        $a \gets$ select$(A)$ \;
        $C'' \gets C'\setminus \{a\} $ \;
        $r \gets $ new-node-with-label$(a)$ \;

        \ForAll{$v \in V_a$}{
            $S'' \gets \{u : u \in S' \land f(u, a) = v\}$ \;
            $t \gets$ \FIDthree{$\mathcal{I}, d, S'', C'', m$} \;
            add-edge$(r, t, v)$ \;
        }

        \KwRet{r}\;
    }
    \caption{ID3}
\end{algorithm}
